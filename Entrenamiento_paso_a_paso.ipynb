{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mimages\u001b[00m\r\n",
      "├── \u001b[01;34mtest\u001b[00m\r\n",
      "│   ├── \u001b[01;34mJPEGImages\u001b[00m\r\n",
      "│   └── \u001b[01;34mVisualization\u001b[00m\r\n",
      "├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   ├── \u001b[01;34mJPEGImages\u001b[00m\r\n",
      "│   └── \u001b[01;34mVisualization\u001b[00m\r\n",
      "└── \u001b[01;34mval\u001b[00m\r\n",
      "    ├── \u001b[01;34mJPEGImages\u001b[00m\r\n",
      "    └── \u001b[01;34mVisualization\u001b[00m\r\n",
      "\r\n",
      "9 directories\r\n"
     ]
    }
   ],
   "source": [
    "!tree -d images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a dividir nuestras imágenes y anotaciones en splits de train, test y validación.\n",
    "# los argumentos -vr y -tr indican respectivamente los porcentajes de datos reservados para validación y test\n",
    "!python3 scripts/train_test_split.py -i images -o images -tr 0.1 -vr 0.15\n",
    "!tree -d images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a convertir estas fotos en y anotaciones en datasets de formato COCO. Tenemos que hacerlo para los sets de train\n",
    "# test y validación. Tenemos que pasar como argumento archivo txt con los labels siguiendo el formato indiado en la\n",
    "# documentación oficial de labelme https://github.com/wkentaro/labelme/tree/master/examples/instance_segmentation. Un ejemplo\n",
    "# de cómo debe ser este archivo se muestra debajo\n",
    "!python3 scripts/labelme2coco.py images/train images/train/coco --labels training/labels.txt\n",
    "!python3 scripts/labelme2coco.py images/test images/test/coco --labels training/labels.txt\n",
    "!python3 scripts/labelme2coco.py images/val images/val/coco --labels training/labels.txt\n",
    "!tree -d images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"training/ejemplo_labels_txt.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora borramos las imágenes y anotaciones de las carpetas train, test y val, ya que la carpeta coco dentro de cada \n",
    "# una de estas carpetas ya contiene las imágenes originales\n",
    "!rm images/test/*\n",
    "!mv images/test/coco/* images/test\n",
    "!rm -rf images/test/coco \n",
    "\n",
    "!rm images/train/*\n",
    "!mv images/train/coco/* images/train\n",
    "!rm -rf images/train/coco \n",
    "\n",
    "!rm images/val/*\n",
    "!mv images/val/coco/* images/val\n",
    "!rm -rf images/val/coco \n",
    "\n",
    "!tree -d images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:29:11.932793 140572526618432 create_coco_tf_record.py:399] Found groundtruth annotations. Building annotations index.\n",
      "I0902 08:29:11.933215 140572526618432 create_coco_tf_record.py:412] 0 images are missing annotations.\n",
      "I0902 08:29:11.933476 140572526618432 create_coco_tf_record.py:441] On image 0 of 117\n",
      "I0902 08:29:35.454863 140572526618432 create_coco_tf_record.py:441] On image 100 of 117\n",
      "I0902 08:29:39.719069 140572526618432 create_coco_tf_record.py:466] Finished writing, skipped 0 annotations.\n",
      "I0902 08:29:39.724019 140572526618432 create_coco_tf_record.py:399] Found groundtruth annotations. Building annotations index.\n",
      "I0902 08:29:39.724163 140572526618432 create_coco_tf_record.py:412] 0 images are missing annotations.\n",
      "I0902 08:29:39.724201 140572526618432 create_coco_tf_record.py:441] On image 0 of 24\n",
      "I0902 08:29:45.580536 140572526618432 create_coco_tf_record.py:466] Finished writing, skipped 0 annotations.\n",
      "I0902 08:29:45.583121 140572526618432 create_coco_tf_record.py:399] Found groundtruth annotations. Building annotations index.\n",
      "I0902 08:29:45.583234 140572526618432 create_coco_tf_record.py:412] 0 images are missing annotations.\n",
      "I0902 08:29:45.583271 140572526618432 create_coco_tf_record.py:441] On image 0 of 16\n",
      "I0902 08:29:48.323288 140572526618432 create_coco_tf_record.py:466] Finished writing, skipped 0 annotations.\n"
     ]
    }
   ],
   "source": [
    "# ahora tenemos que generar los tfrecords usando estos dataset en formato coco\n",
    "!python3 object_detection/dataset_tools/create_coco_tf_record.py --logtostderr \\\n",
    "--train_image_dir=images/train \\\n",
    "--val_image_dir=images/val \\\n",
    "--test_image_dir=images/test \\\n",
    "--train_annotations_file=images/train/annotations.json \\\n",
    "--val_annotations_file=images/val/annotations.json \\\n",
    "--testdev_annotations_file=images/test/annotations.json \\\n",
    "--output_dir=training/tfrecords \\\n",
    "--include_masks=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0902 08:54:14.865653 139718703343424 model_lib.py:771] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 400000\n",
      "I0902 08:54:14.865819 139718703343424 config_util.py:552] Maybe overwriting train_steps: 400000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0902 08:54:14.865867 139718703343424 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I0902 08:54:14.865906 139718703343424 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0902 08:54:14.865944 139718703343424 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0902 08:54:14.865996 139718703343424 model_lib.py:787] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "I0902 08:54:14.866042 139718703343424 model_lib.py:822] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f12215e1690>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0902 08:54:14.866323 139718703343424 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f12215e1690>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f12220c4320>) includes params argument, but params are not passed to Estimator.\n",
      "W0902 08:54:14.866553 139718703343424 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f12220c4320>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I0902 08:54:14.866847 139718703343424 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0902 08:54:14.866945 139718703343424 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0902 08:54:14.867070 139718703343424 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0902 08:54:14.870412 139718703343424 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0902 08:54:14.890719 139718703343424 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0902 08:54:14.904694 139718703343424 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0902 08:54:23.050754 139718703343424 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0902 08:54:23.117555 139718703343424 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0902 08:54:26.486461 139718703343424 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0902 08:54:29.321695 139718703343424 estimator.py:1148] Calling model_fn.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0902 08:54:29.346276 139718703343424 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0902 08:54:30.275948 139718703343424 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0902 08:54:30.367708 139718703343424 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0902 08:54:30.367954 139718703343424 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0902 08:54:30.851976 139718703343424 deprecation.py:506] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0902 08:54:31.173233 139718703343424 deprecation.py:323] From /home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0902 08:54:31.174717 139718703343424 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0902 08:54:31.184982 139718703343424 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0902 08:54:31.200404 139718703343424 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/core/losses.py:380: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0902 08:54:31.411290 139718703343424 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/core/losses.py:380: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "/home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/bigdata/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0902 08:54:34.087956 139718703343424 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0902 08:54:34.088881 139718703343424 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0902 08:54:35.536108 139718703343424 monitored_session.py:240] Graph was finalized.\n",
      "2020-09-02 08:54:35.536412: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-09-02 08:54:35.560717: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3799900000 Hz\n",
      "2020-09-02 08:54:35.561952: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56139277b750 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-09-02 08:54:35.562002: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-09-02 08:54:35.566060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-09-02 08:54:35.821273: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56139277b3c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-09-02 08:54:35.821338: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n",
      "2020-09-02 08:54:35.821367: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080, Compute Capability 6.1\n",
      "2020-09-02 08:54:35.829414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2020-09-02 08:54:35.830407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2020-09-02 08:54:35.830927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-09-02 08:54:35.833213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-09-02 08:54:35.835213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-09-02 08:54:35.835821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-09-02 08:54:35.838412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-09-02 08:54:35.840338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-09-02 08:54:35.846194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-02 08:54:35.848677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-09-02 08:54:35.848743: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-09-02 08:54:35.850862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-09-02 08:54:35.850886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-09-02 08:54:35.850901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2020-09-02 08:54:35.850913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2020-09-02 08:54:35.852861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7408 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2020-09-02 08:54:35.854063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7603 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "I0902 08:54:38.254704 139718703343424 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0902 08:54:38.453642 139718703343424 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
      "I0902 08:54:42.393664 139718703343424 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
      "2020-09-02 08:54:47.051249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-09-02 08:54:50.459196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-02 08:54:52.481956: W tensorflow/stream_executor/cuda/ptxas_utils.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.\n",
      "INFO:tensorflow:loss = 5.928209, step = 0\n",
      "I0902 08:54:55.226454 139718703343424 basic_session_run_hooks.py:262] loss = 5.928209, step = 0\n",
      "INFO:tensorflow:global_step/sec: 4.02753\n",
      "I0902 08:55:20.054469 139718703343424 basic_session_run_hooks.py:692] global_step/sec: 4.02753\n",
      "INFO:tensorflow:loss = 4.3407817, step = 100 (24.829 sec)\n",
      "I0902 08:55:20.055668 139718703343424 basic_session_run_hooks.py:260] loss = 4.3407817, step = 100 (24.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5502\n",
      "I0902 08:55:42.031430 139718703343424 basic_session_run_hooks.py:692] global_step/sec: 4.5502\n",
      "INFO:tensorflow:loss = 4.8353868, step = 200 (21.977 sec)\n",
      "I0902 08:55:42.032155 139718703343424 basic_session_run_hooks.py:260] loss = 4.8353868, step = 200 (21.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.53113\n",
      "I0902 08:56:04.100997 139718703343424 basic_session_run_hooks.py:692] global_step/sec: 4.53113\n",
      "INFO:tensorflow:loss = 2.0953434, step = 300 (22.070 sec)\n",
      "I0902 08:56:04.101786 139718703343424 basic_session_run_hooks.py:260] loss = 2.0953434, step = 300 (22.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.56455\n",
      "I0902 08:56:26.008992 139718703343424 basic_session_run_hooks.py:692] global_step/sec: 4.56455\n",
      "INFO:tensorflow:loss = 5.2470694, step = 400 (21.908 sec)\n",
      "I0902 08:56:26.010124 139718703343424 basic_session_run_hooks.py:260] loss = 5.2470694, step = 400 (21.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50254\n",
      "I0902 08:56:48.218611 139718703343424 basic_session_run_hooks.py:692] global_step/sec: 4.50254\n",
      "INFO:tensorflow:loss = 4.5709047, step = 500 (22.214 sec)\n",
      "I0902 08:56:48.224088 139718703343424 basic_session_run_hooks.py:260] loss = 4.5709047, step = 500 (22.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.55556\n",
      "I0902 08:57:10.169867 139718703343424 basic_session_run_hooks.py:692] global_step/sec: 4.55556\n",
      "INFO:tensorflow:loss = 2.9779685, step = 600 (21.947 sec)\n",
      "I0902 08:57:10.171141 139718703343424 basic_session_run_hooks.py:260] loss = 2.9779685, step = 600 (21.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48345\n",
      "I0902 08:57:32.474097 139718703343424 basic_session_run_hooks.py:692] global_step/sec: 4.48345\n",
      "INFO:tensorflow:loss = 3.7899015, step = 700 (22.304 sec)\n",
      "I0902 08:57:32.475137 139718703343424 basic_session_run_hooks.py:260] loss = 3.7899015, step = 700 (22.304 sec)\n"
     ]
    }
   ],
   "source": [
    "# entrenamos el modelo usando estos tfrecords\n",
    "!python3 object_detection/model_main.py --alsologtostderr \\\n",
    "--model_dir=training/ \\\n",
    "--pipeline_config_path=training/mask_rcnn_inception_v2_coco.config \\\n",
    "--num_train_steps=400000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
