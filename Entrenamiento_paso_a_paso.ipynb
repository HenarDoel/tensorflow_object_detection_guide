{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instalación de paquetes y verificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congrats, you are using 3.7.9  which is compatible with this notebook\n"
     ]
    }
   ],
   "source": [
    "# comprobamos que la versión de python sea inferior a 3.8, ya que para usar tensorflow 1.15 se recomienda usar python\n",
    "# 3.7 o inferior\n",
    "import sys\n",
    "import string\n",
    "python_version=sys.version.split(\"(\")[0]\n",
    "if int(sys.version.split(\".\")[1])>7:\n",
    "    print(\"you are using a python version higer than 3.7.x, please install python 3.7.x\")\n",
    "else:\n",
    "    print(\"congrats, you are using {} which is compatible with this notebook\".format(python_version))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: './object-detection' (from line 29 of requirements.txt)\r\n",
      "Hint: It looks like a path. File './object-detection' does not exist.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# vamos a instalar todos los paquetes necesarios para el funcionamiento de este cuaderno. Este cuaderno, junto con el\n",
    "# repo de github con las carpetas y archivos nos ahorran tener que seguir el proceso descrito aqu: \n",
    "# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1.md\n",
    "# y además nos evitan posibles problemas\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.7.9: /home/bigdata/anaconda3/envs/test/bin/python3\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n",
      "/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/data_structures.py:669: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if not isinstance(wrapped_dict, collections.Mapping):\n",
      "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_experimental_model\n",
      "[       OK ] ModelBuilderTF1Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF1Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF1Test.test_session\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 21 tests in 0.085s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# si todo sale bien,el test debería correr y los resultados aparecerán debajo. Es normal si se salta alguno de los tests \n",
    "# que hay\n",
    "!python3 object_detection/builders/model_builder_tf1_test.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succesfully created validation split using:  15.0 % of data\n",
      "succesfully created test split using:  10.0 % of data\n",
      "succesfully created train split using:  75.0 % of data\n",
      "\u001b[01;34mimages\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "\n",
      "3 directories\n"
     ]
    }
   ],
   "source": [
    "# vamos a dividir nuestras imágenes y anotaciones en splits de train, test y validación.\n",
    "# los argumentos -vr y -tr indican respectivamente los porcentajes de datos reservados para validación y test\n",
    "!python3 scripts/train_test_split.py -i images -o images -tr 0.1 -vr 0.15\n",
    "!tree -d images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset: images/train/coco\n",
      "Generating dataset from: images/train/images_frame2000.json\n",
      "Generating dataset from: images/train/images_frame8050.json\n",
      "Generating dataset from: images/train/images_frame3100.json\n",
      "Generating dataset from: images/train/images_frame2750.json\n",
      "Generating dataset from: images/train/images_frame7900.json\n",
      "Generating dataset from: images/train/images_frame5800.json\n",
      "Generating dataset from: images/train/images_frame10250.json\n",
      "Generating dataset from: images/train/images_frame5300.json\n",
      "Generating dataset from: images/train/images_frame2950.json\n",
      "Generating dataset from: images/train/images_frame3750.json\n",
      "Generating dataset from: images/train/images_frame10150.json\n",
      "Generating dataset from: images/train/images_frame1700.json\n",
      "Generating dataset from: images/train/images_frame5150.json\n",
      "Generating dataset from: images/train/images_frame10050.json\n",
      "Generating dataset from: images/train/images_frame7350.json\n",
      "Generating dataset from: images/train/images_frame1350.json\n",
      "Generating dataset from: images/train/images_frame3350.json\n",
      "Generating dataset from: images/train/images_frame8500.json\n",
      "Generating dataset from: images/train/images_frame1550.json\n",
      "Generating dataset from: images/train/images_frame9400.json\n",
      "Generating dataset from: images/train/images_frame9200.json\n",
      "Generating dataset from: images/train/images_frame10100.json\n",
      "Generating dataset from: images/train/images_frame9650.json\n",
      "Generating dataset from: images/train/images_frame3150.json\n",
      "Generating dataset from: images/train/images_frame7450.json\n",
      "Generating dataset from: images/train/images_frame5450.json\n",
      "Generating dataset from: images/train/images_frame3250.json\n",
      "Generating dataset from: images/train/images_frame9100.json\n",
      "Generating dataset from: images/train/images_frame900.json\n",
      "Generating dataset from: images/train/images_frame9750.json\n",
      "Generating dataset from: images/train/images_frame9000.json\n",
      "Generating dataset from: images/train/images_frame9950.json\n",
      "Generating dataset from: images/train/images_frame8450.json\n",
      "Generating dataset from: images/train/images_frame2350.json\n",
      "Generating dataset from: images/train/images_frame5700.json\n",
      "Generating dataset from: images/train/images_frame2500.json\n",
      "Generating dataset from: images/train/images_frame9700.json\n",
      "Generating dataset from: images/train/images_frame2100.json\n",
      "Generating dataset from: images/train/images_frame4850.json\n",
      "Generating dataset from: images/train/images_frame9600.json\n",
      "Generating dataset from: images/train/images_frame1050.json\n",
      "Generating dataset from: images/train/images_frame4550.json\n",
      "Generating dataset from: images/train/images_frame7650.json\n",
      "Generating dataset from: images/train/images_frame9250.json\n",
      "Generating dataset from: images/train/images_frame7000.json\n",
      "Generating dataset from: images/train/images_frame1450.json\n",
      "Generating dataset from: images/train/images_frame4000.json\n",
      "Generating dataset from: images/train/images_frame8150.json\n",
      "Generating dataset from: images/train/images_frame5250.json\n",
      "Generating dataset from: images/train/images_frame3200.json\n",
      "Generating dataset from: images/train/images_frame6950.json\n",
      "Generating dataset from: images/train/images_frame4500.json\n",
      "Generating dataset from: images/train/images_frame3700.json\n",
      "Generating dataset from: images/train/images_frame1000.json\n",
      "Generating dataset from: images/train/images_frame4400.json\n",
      "Generating dataset from: images/train/images_frame2600.json\n",
      "Generating dataset from: images/train/images_frame9350.json\n",
      "Generating dataset from: images/train/images_frame3550.json\n",
      "Generating dataset from: images/train/images_frame2200.json\n",
      "Generating dataset from: images/train/images_frame8900.json\n",
      "Generating dataset from: images/train/images_frame8250.json\n",
      "Generating dataset from: images/train/images_frame1300.json\n",
      "Generating dataset from: images/train/images_frame7600.json\n",
      "Generating dataset from: images/train/images_frame1950.json\n",
      "Generating dataset from: images/train/images_frame7050.json\n",
      "Generating dataset from: images/train/images_frame4250.json\n",
      "Generating dataset from: images/train/images_frame7700.json\n",
      "Generating dataset from: images/train/images_frame2400.json\n",
      "Generating dataset from: images/train/images_frame5350.json\n",
      "Generating dataset from: images/train/images_frame4950.json\n",
      "Generating dataset from: images/train/images_frame8850.json\n",
      "Generating dataset from: images/train/images_frame7550.json\n",
      "Generating dataset from: images/train/images_frame8750.json\n",
      "Generating dataset from: images/train/images_frame950.json\n",
      "Generating dataset from: images/train/images_frame7400.json\n",
      "Generating dataset from: images/train/images_frame3800.json\n",
      "Generating dataset from: images/train/images_frame8550.json\n",
      "Generating dataset from: images/train/images_frame9800.json\n",
      "Generating dataset from: images/train/images_frame7300.json\n",
      "Generating dataset from: images/train/images_frame1400.json\n",
      "Generating dataset from: images/train/images_frame7100.json\n",
      "Generating dataset from: images/train/images_frame9050.json\n",
      "Generating dataset from: images/train/images_frame8350.json\n",
      "Generating dataset from: images/train/images_frame5750.json\n",
      "Generating dataset from: images/train/images_frame7950.json\n",
      "Generating dataset from: images/train/images_frame4800.json\n",
      "Generating dataset from: images/train/images_frame3450.json\n",
      "Generating dataset from: images/train/images_frame4900.json\n",
      "Generating dataset from: images/train/images_frame9500.json\n",
      "Generating dataset from: images/train/images_frame4350.json\n",
      "Generating dataset from: images/train/images_frame4200.json\n",
      "Generating dataset from: images/train/images_frame8600.json\n",
      "Generating dataset from: images/train/images_frame4050.json\n",
      "Generating dataset from: images/train/images_frame3050.json\n",
      "Generating dataset from: images/train/images_frame7150.json\n",
      "Generating dataset from: images/train/images_frame2450.json\n",
      "Generating dataset from: images/train/images_frame2550.json\n",
      "Generating dataset from: images/train/images_frame1500.json\n",
      "Generating dataset from: images/train/images_frame1100.json\n",
      "Generating dataset from: images/train/images_frame8950.json\n",
      "Generating dataset from: images/train/images_frame8200.json\n",
      "Generating dataset from: images/train/images_frame9300.json\n",
      "Generating dataset from: images/train/images_frame4750.json\n",
      "Generating dataset from: images/train/images_frame8100.json\n",
      "Generating dataset from: images/train/images_frame3850.json\n",
      "Generating dataset from: images/train/images_frame1600.json\n",
      "Generating dataset from: images/train/images_frame7250.json\n",
      "Generating dataset from: images/train/images_frame9850.json\n",
      "Generating dataset from: images/train/images_frame10200.json\n",
      "Generating dataset from: images/train/images_frame8300.json\n",
      "Generating dataset from: images/train/images_frame8650.json\n",
      "Generating dataset from: images/train/images_frame4700.json\n",
      "Generating dataset from: images/train/images_frame4650.json\n",
      "Generating dataset from: images/train/images_frame3650.json\n",
      "Generating dataset from: images/train/images_frame4600.json\n",
      "Generating dataset from: images/train/images_frame3600.json\n",
      "Generating dataset from: images/train/images_frame3900.json\n",
      "Creating dataset: images/test/coco\n",
      "Generating dataset from: images/test/images_frame1750.json\n",
      "Generating dataset from: images/test/images_frame2050.json\n",
      "Generating dataset from: images/test/images_frame3300.json\n",
      "Generating dataset from: images/test/images_frame1250.json\n",
      "Generating dataset from: images/test/images_frame2650.json\n",
      "Generating dataset from: images/test/images_frame6900.json\n",
      "Generating dataset from: images/test/images_frame3400.json\n",
      "Generating dataset from: images/test/images_frame5550.json\n",
      "Generating dataset from: images/test/images_frame7850.json\n",
      "Generating dataset from: images/test/images_frame7200.json\n",
      "Generating dataset from: images/test/images_frame2250.json\n",
      "Generating dataset from: images/test/images_frame7500.json\n",
      "Generating dataset from: images/test/images_frame7800.json\n",
      "Generating dataset from: images/test/images_frame9900.json\n",
      "Generating dataset from: images/test/images_frame3950.json\n",
      "Generating dataset from: images/test/images_frame1150.json\n",
      "Creating dataset: images/val/coco\n",
      "Generating dataset from: images/val/images_frame5200.json\n",
      "Generating dataset from: images/val/images_frame8700.json\n",
      "Generating dataset from: images/val/images_frame2300.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset from: images/val/images_frame8800.json\n",
      "Generating dataset from: images/val/images_frame8400.json\n",
      "Generating dataset from: images/val/images_frame1650.json\n",
      "Generating dataset from: images/val/images_frame9450.json\n",
      "Generating dataset from: images/val/images_frame1200.json\n",
      "Generating dataset from: images/val/images_frame7750.json\n",
      "Generating dataset from: images/val/images_frame5500.json\n",
      "Generating dataset from: images/val/images_frame2900.json\n",
      "Generating dataset from: images/val/images_frame10000.json\n",
      "Generating dataset from: images/val/images_frame4300.json\n",
      "Generating dataset from: images/val/images_frame3000.json\n",
      "Generating dataset from: images/val/images_frame9150.json\n",
      "Generating dataset from: images/val/images_frame2150.json\n",
      "Generating dataset from: images/val/images_frame9550.json\n",
      "Generating dataset from: images/val/images_frame4100.json\n",
      "Generating dataset from: images/val/images_frame4450.json\n",
      "Generating dataset from: images/val/images_frame2700.json\n",
      "Generating dataset from: images/val/images_frame8000.json\n",
      "Generating dataset from: images/val/images_frame10300.json\n",
      "Generating dataset from: images/val/images_frame3500.json\n",
      "Generating dataset from: images/val/images_frame4150.json\n",
      "\u001b[01;34mimages\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "│   └── \u001b[01;34mcoco\u001b[00m\n",
      "│       ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "│       └── \u001b[01;34mVisualization\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   └── \u001b[01;34mcoco\u001b[00m\n",
      "│       ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "│       └── \u001b[01;34mVisualization\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "    └── \u001b[01;34mcoco\u001b[00m\n",
      "        ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "        └── \u001b[01;34mVisualization\u001b[00m\n",
      "\n",
      "12 directories\n"
     ]
    }
   ],
   "source": [
    "# vamos a convertir estas fotos en y anotaciones en datasets de formato COCO. Tenemos que hacerlo para los sets de train\n",
    "# test y validación. Tenemos que pasar como argumento archivo txt con los labels siguiendo el formato indiado en la\n",
    "# documentación oficial de labelme https://github.com/wkentaro/labelme/tree/master/examples/instance_segmentation. Un ejemplo\n",
    "# de cómo debe ser este archivo se muestra debajo\n",
    "!python3 scripts/labelme2coco.py images/train images/train/coco --labels training/labels.txt\n",
    "!python3 scripts/labelme2coco.py images/test images/test/coco --labels training/labels.txt\n",
    "!python3 scripts/labelme2coco.py images/val images/val/coco --labels training/labels.txt\n",
    "!tree -d images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"training/ejemplo_labels_txt.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'images/test/coco': Is a directory\n",
      "rm: cannot remove 'images/train/coco': Is a directory\n",
      "rm: cannot remove 'images/val/coco': Is a directory\n",
      "\u001b[01;34mimages\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "│   ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "│   └── \u001b[01;34mVisualization\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "│   └── \u001b[01;34mVisualization\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "    ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "    └── \u001b[01;34mVisualization\u001b[00m\n",
      "\n",
      "9 directories\n"
     ]
    }
   ],
   "source": [
    "# ahora borramos las imágenes y anotaciones de las carpetas train, test y val, ya que la carpeta coco dentro de cada \n",
    "# una de estas carpetas ya contiene las imágenes originales\n",
    "!rm images/test/*\n",
    "!mv images/test/coco/* images/test\n",
    "!rm -rf images/test/coco \n",
    "\n",
    "!rm images/train/*\n",
    "!mv images/train/coco/* images/train\n",
    "!rm -rf images/train/coco \n",
    "\n",
    "!rm images/val/*\n",
    "!mv images/val/coco/* images/val\n",
    "!rm -rf images/val/coco \n",
    "\n",
    "!tree -d images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0903 07:02:14.021196 140190018115392 create_coco_tf_record.py:399] Found groundtruth annotations. Building annotations index.\n",
      "I0903 07:02:14.021518 140190018115392 create_coco_tf_record.py:412] 0 images are missing annotations.\n",
      "I0903 07:02:14.021673 140190018115392 create_coco_tf_record.py:441] On image 0 of 117\n",
      "I0903 07:02:37.000346 140190018115392 create_coco_tf_record.py:441] On image 100 of 117\n",
      "I0903 07:02:41.302762 140190018115392 create_coco_tf_record.py:466] Finished writing, skipped 0 annotations.\n",
      "I0903 07:02:41.307433 140190018115392 create_coco_tf_record.py:399] Found groundtruth annotations. Building annotations index.\n",
      "I0903 07:02:41.307577 140190018115392 create_coco_tf_record.py:412] 0 images are missing annotations.\n",
      "I0903 07:02:41.307616 140190018115392 create_coco_tf_record.py:441] On image 0 of 24\n",
      "I0903 07:02:46.662210 140190018115392 create_coco_tf_record.py:466] Finished writing, skipped 0 annotations.\n",
      "I0903 07:02:46.665430 140190018115392 create_coco_tf_record.py:399] Found groundtruth annotations. Building annotations index.\n",
      "I0903 07:02:46.665534 140190018115392 create_coco_tf_record.py:412] 0 images are missing annotations.\n",
      "I0903 07:02:46.665571 140190018115392 create_coco_tf_record.py:441] On image 0 of 16\n",
      "I0903 07:02:50.661790 140190018115392 create_coco_tf_record.py:466] Finished writing, skipped 0 annotations.\n"
     ]
    }
   ],
   "source": [
    "# ahora tenemos que generar los tfrecords usando estos dataset en formato coco\n",
    "!python3 object_detection/dataset_tools/create_coco_tf_record.py --logtostderr \\\n",
    "--train_image_dir=images/train \\\n",
    "--val_image_dir=images/val \\\n",
    "--test_image_dir=images/test \\\n",
    "--train_annotations_file=images/train/annotations.json \\\n",
    "--val_annotations_file=images/val/annotations.json \\\n",
    "--testdev_annotations_file=images/test/annotations.json \\\n",
    "--output_dir=training/tfrecord \\\n",
    "--include_masks=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y exportación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0903 07:16:13.516900 140078348080960 model_lib.py:771] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 400000\n",
      "I0903 07:16:13.517046 140078348080960 config_util.py:552] Maybe overwriting train_steps: 400000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0903 07:16:13.517093 140078348080960 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I0903 07:16:13.517131 140078348080960 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0903 07:16:13.517168 140078348080960 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0903 07:16:13.517218 140078348080960 model_lib.py:787] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "I0903 07:16:13.517262 140078348080960 model_lib.py:822] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f65de5426d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0903 07:16:13.517533 140078348080960 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f65de5426d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f65de53b710>) includes params argument, but params are not passed to Estimator.\n",
      "W0903 07:16:13.517739 140078348080960 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f65de53b710>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I0903 07:16:13.517955 140078348080960 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0903 07:16:13.518049 140078348080960 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0903 07:16:13.518169 140078348080960 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0903 07:16:13.524251 140078348080960 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0903 07:16:13.544540 140078348080960 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0903 07:16:13.558691 140078348080960 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0903 07:16:21.798357 140078348080960 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0903 07:16:21.922397 140078348080960 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0903 07:16:26.169020 140078348080960 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"object_detection/model_main.py\", line 108, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/absl/app.py\", line 300, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"object_detection/model_main.py\", line 104, in main\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
      "    return self.run_local()\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1188, in _train_model_default\n",
      "    input_fn, ModeKeys.TRAIN))\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n",
      "    self._call_input_fn(input_fn, mode))\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1116, in _call_input_fn\n",
      "    return input_fn(**kwargs)\n",
      "  File \"/home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/inputs.py\", line 698, in _train_input_fn\n",
      "    params=params)\n",
      "  File \"/home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/inputs.py\", line 838, in train_input\n",
      "    reduce_to_frame_fn=reduce_to_frame_fn)\n",
      "  File \"/home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/builders/dataset_builder.py\", line 196, in build\n",
      "    batch_size, input_reader_config)\n",
      "  File \"/home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/builders/dataset_builder.py\", line 175, in dataset_map_fn\n",
      "    fn_to_map, num_parallel_calls=num_parallel_calls)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 1950, in map_with_legacy_function\n",
      "    use_legacy_function=True))\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3472, in __init__\n",
      "    use_legacy_function=use_legacy_function)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2689, in __init__\n",
      "    self._function.add_to_graph(ops.get_default_graph())\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/function.py\", line 545, in add_to_graph\n",
      "    self._create_definition_if_needed()\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/function.py\", line 377, in _create_definition_if_needed\n",
      "    self._create_definition_if_needed_impl()\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/function.py\", line 408, in _create_definition_if_needed_impl\n",
      "    capture_resource_var_by_value=self._capture_resource_var_by_value)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/function.py\", line 944, in func_graph_from_py_func\n",
      "    outputs = func(*func_graph.inputs)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2681, in wrapper_fn\n",
      "    ret = _wrapper_helper(*args)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2652, in _wrapper_helper\n",
      "    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 234, in wrapper\n",
      "    return converted_call(f, options, args, kwargs)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "  File \"/tmp/tmpn7p_p6w3.py\", line 29, in tf__transform_and_pad_input_data_fn\n",
      "    retval_ = transform_and_pad_input_data_fn_scope.mark_return_value((ag__.converted_call(_get_features_dict, transform_and_pad_input_data_fn_scope.callopts, (tensor_dict, include_source_id), None, transform_and_pad_input_data_fn_scope), ag__.converted_call(_get_labels_dict, transform_and_pad_input_data_fn_scope.callopts, (tensor_dict,), None, transform_and_pad_input_data_fn_scope)))\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 506, in converted_call\n",
      "    converted_f = conversion.convert(target_entity, program_ctx)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 322, in convert\n",
      "    free_nonglobal_var_names)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 240, in _convert_with_cache\n",
      "    entity, program_ctx)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 469, in convert_entity_to_ast\n",
      "    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 669, in convert_func_to_ast\n",
      "    node = node_to_graph(node, context)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 698, in node_to_graph\n",
      "    node = converter.standard_analysis(node, context, is_initial=True)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/core/converter.py\", line 384, in standard_analysis\n",
      "    node = activity.resolve(node, context, None)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 498, in resolve\n",
      "    return ActivityAnalyzer(context, parent_scope).visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n",
      "    result = super(Base, self).visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/ast.py\", line 271, in visit\n",
      "    return visitor(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 442, in visit_FunctionDef\n",
      "    node.body = self.visit_block(node.body)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 371, in visit_block\n",
      "    replacement = self.visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n",
      "    result = super(Base, self).visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/ast.py\", line 271, in visit\n",
      "    return visitor(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 467, in visit_If\n",
      "    (node.orelse, NodeAnno.ORELSE_SCOPE)))\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 352, in _process_parallel_blocks\n",
      "    parent = self._process_block_node(parent, child, scope_name)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 338, in _process_block_node\n",
      "    block = self.visit_block(block)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 371, in visit_block\n",
      "    replacement = self.visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n",
      "    result = super(Base, self).visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/ast.py\", line 271, in visit\n",
      "    return visitor(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 272, in visit_Assign\n",
      "    return self._process_statement(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 260, in _process_statement\n",
      "    node = self.generic_visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/ast.py\", line 335, in generic_visit\n",
      "    new_node = self.visit(old_value)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n",
      "    result = super(Base, self).visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/ast.py\", line 271, in visit\n",
      "    return visitor(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 309, in visit_Subscript\n",
      "    node = self.generic_visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/ast.py\", line 335, in generic_visit\n",
      "    new_node = self.visit(old_value)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n",
      "    result = super(Base, self).visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/ast.py\", line 271, in visit\n",
      "    return visitor(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/ast.py\", line 335, in generic_visit\n",
      "    new_node = self.visit(old_value)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py\", line 480, in visit\n",
      "    result = super(Base, self).visit(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/ast.py\", line 271, in visit\n",
      "    return visitor(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 305, in visit_Attribute\n",
      "    self._track_symbol(node)\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py\", line 196, in _track_symbol\n",
      "    if not anno.hasanno(node, anno.Basic.QN):\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/anno.py\", line 113, in hasanno\n",
      "    return hasattr(node, field_name) and key in getattr(node, field_name)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# entrenamos el modelo usando estos tfrecords. El modelo resultante se guardará el carpeta training\n",
    "!python3 object_detection/model_main.py --alsologtostderr \\\n",
    "--model_dir=training/ \\\n",
    "--pipeline_config_path=training/mask_rcnn_inception_v2_coco.config \\\n",
    "--num_train_steps=400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "ejemplo_labels_txt.PNG\r\n",
      "eval_0\r\n",
      "events.out.tfevents.1599116611.bigdata-alineware\r\n",
      "faster_rcnn_inception_v2_coco.config\r\n",
      "graph.pbtxt\r\n",
      "label_map.pbtxt\r\n",
      "labels.txt\r\n",
      "mask_rcnn_inception_v2_coco.config\r\n",
      "model.ckpt-0.data-00000-of-00001\r\n",
      "model.ckpt-0.index\r\n",
      "model.ckpt-0.meta\r\n",
      "model.ckpt-2744.data-00000-of-00001\r\n",
      "model.ckpt-2744.index\r\n",
      "model.ckpt-2744.meta\r\n",
      "tfrecord\r\n"
     ]
    }
   ],
   "source": [
    "# aquí nos vamos a fijar en los archivos model.ckpt y vamos a buscar el que tenga el número más alto, ya que este número\n",
    "# indica el step del proceso de entrenamiento en el que se realizó el checkpoint del modelo\n",
    "!dir training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el campo trained_checkpoint debes poner lo siguiente: \n",
      "training/model.ckpt-2744\n"
     ]
    }
   ],
   "source": [
    "# por si no lo ves claro, corriendo esto te dirá qué debes poner en el script siguiente que generará el grafo de inferencia\n",
    "import glob\n",
    "import os\n",
    "max_step=0\n",
    "for file in glob.glob(\"training/*\"):\n",
    "    if (\"model.ckpt\" in  file):\n",
    "        step=int (file.split(os.sep)[1].split(\".\")[1].split(\"-\")[1])\n",
    "        max_step= step if step>max_step else max_step\n",
    "print(\"En el campo trained_checkpoint debes poner lo siguiente: \\ntraining/model.ckpt-\"+str(max_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0903 07:15:05.191840 140518929565504 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0903 07:15:06.003338 140518929565504 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0903 07:15:06.093859 140518929565504 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0903 07:15:06.094101 140518929565504 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/core/box_list_ops.py:166: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0903 07:15:06.127783 140518929565504 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/core/box_list_ops.py:166: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0903 07:15:06.480877 140518929565504 deprecation.py:506] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0903 07:15:06.806371 140518929565504 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0903 07:15:06.809829 140518929565504 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0903 07:15:06.822246 140518929565504 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "W0903 07:15:07.333450 140518929565504 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0903 07:15:07.527866 140518929565504 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Removing rpn_box_predictor_features from prediction_dict\n",
      "I0903 07:15:07.554516 140518929565504 faster_rcnn_meta_arch.py:1565] Removing rpn_box_predictor_features from prediction_dict\n",
      "INFO:tensorflow:Removing rpn_features_to_crop from prediction_dict\n",
      "I0903 07:15:07.554644 140518929565504 faster_rcnn_meta_arch.py:1565] Removing rpn_features_to_crop from prediction_dict\n",
      "INFO:tensorflow:Removing feature_maps from prediction_dict\n",
      "I0903 07:15:07.554683 140518929565504 faster_rcnn_meta_arch.py:1565] Removing feature_maps from prediction_dict\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0903 07:15:07.557293 140518929565504 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "W0903 07:15:07.559263 140518929565504 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "W0903 07:15:07.559999 140518929565504 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "242 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/13.15m params)\n",
      "  Conv (--/2.65m params)\n",
      "    Conv/biases (512, 512/512 params)\n",
      "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
      "  FirstStageBoxPredictor (--/36.94k params)\n",
      "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
      "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
      "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
      "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
      "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
      "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
      "  FirstStageFeatureExtractor (--/4.25m params)\n",
      "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "  SecondStageBoxPredictor (--/317.62k params)\n",
      "    SecondStageBoxPredictor/BoxEncodingPredictor (--/16.40k params)\n",
      "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (16, 16/16 params)\n",
      "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x16, 16.38k/16.38k params)\n",
      "    SecondStageBoxPredictor/ClassPredictor (--/5.12k params)\n",
      "      SecondStageBoxPredictor/ClassPredictor/biases (5, 5/5 params)\n",
      "      SecondStageBoxPredictor/ClassPredictor/weights (1024x5, 5.12k/5.12k params)\n",
      "    SecondStageBoxPredictor/Conv (--/294.94k params)\n",
      "      SecondStageBoxPredictor/Conv/biases (32, 32/32 params)\n",
      "      SecondStageBoxPredictor/Conv/weights (3x3x1024x32, 294.91k/294.91k params)\n",
      "    SecondStageBoxPredictor/Conv_1 (--/1.16k params)\n",
      "      SecondStageBoxPredictor/Conv_1/biases (4, 4/4 params)\n",
      "      SecondStageBoxPredictor/Conv_1/weights (3x3x32x4, 1.15k/1.15k params)\n",
      "  SecondStageFeatureExtractor (--/5.89m params)\n",
      "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
      "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
      "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.17k flops)\n",
      "  map_3/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
      "  map_2/while/mul (300/300 flops)\n",
      "  map_2/while/mul_1 (300/300 flops)\n",
      "  map_2/while/mul_2 (300/300 flops)\n",
      "  map_2/while/mul_3 (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Maximum (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Minimum (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
      "  map_3/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
      "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
      "  GridAnchorGenerator/truediv (12/12 flops)\n",
      "  GridAnchorGenerator/mul (12/12 flops)\n",
      "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
      "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
      "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
      "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
      "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  mul_1 (1/1 flops)\n",
      "  mul (1/1 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  map_3/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  map_3/while/Less_1 (1/1 flops)\n",
      "  map_3/while/Less (1/1 flops)\n",
      "  map_2/while/Less_1 (1/1 flops)\n",
      "  map_2/while/Less (1/1 flops)\n",
      "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  map_1/while/Less_1 (1/1 flops)\n",
      "  map_1/while/Less (1/1 flops)\n",
      "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
      "  map/while/Less_1 (1/1 flops)\n",
      "  map/while/Less (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  BatchGather/mul_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/Less (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/Less_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  BatchGather/mul (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression_1/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-03 07:15:09.197737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-09-03 07:15:09.311350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2020-09-03 07:15:09.312057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2020-09-03 07:15:09.347993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-09-03 07:15:09.351125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-09-03 07:15:09.353462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-09-03 07:15:09.354085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-09-03 07:15:09.357312: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-09-03 07:15:09.359775: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-09-03 07:15:09.387699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-03 07:15:09.392494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-09-03 07:15:09.404347: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-09-03 07:15:09.436646: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3799900000 Hz\n",
      "2020-09-03 07:15:09.438130: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5633b52274d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-09-03 07:15:09.438174: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-09-03 07:15:09.705508: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5633b86e4750 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-09-03 07:15:09.705544: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n",
      "2020-09-03 07:15:09.705552: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080, Compute Capability 6.1\n",
      "2020-09-03 07:15:09.707793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2020-09-03 07:15:09.708559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2020-09-03 07:15:09.708626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-09-03 07:15:09.708649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-09-03 07:15:09.708669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-09-03 07:15:09.708689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-09-03 07:15:09.708708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-09-03 07:15:09.708728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-09-03 07:15:09.708748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-03 07:15:09.711518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-09-03 07:15:09.711569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-09-03 07:15:09.713979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-09-03 07:15:09.714004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-09-03 07:15:09.714017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2020-09-03 07:15:09.714028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2020-09-03 07:15:09.716162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7408 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2020-09-03 07:15:09.719696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7603 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-2744\n",
      "I0903 07:15:09.722634 140518929565504 saver.py:1284] Restoring parameters from training/model.ckpt-2744\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0903 07:15:11.280107 140518929565504 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2020-09-03 07:15:11.832381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2020-09-03 07:15:11.832764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2020-09-03 07:15:11.832807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-09-03 07:15:11.832817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-09-03 07:15:11.832826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-09-03 07:15:11.832834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-09-03 07:15:11.832842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-09-03 07:15:11.832851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-09-03 07:15:11.832860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-03 07:15:11.833872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-09-03 07:15:11.833921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-09-03 07:15:11.833928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-09-03 07:15:11.833933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2020-09-03 07:15:11.833938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2020-09-03 07:15:11.834696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7408 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2020-09-03 07:15:11.835014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7603 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-2744\n",
      "I0903 07:15:11.836155 140518929565504 saver.py:1284] Restoring parameters from training/model.ckpt-2744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0903 07:15:12.654336 140518929565504 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W0903 07:15:12.654532 140518929565504 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 360 variables.\n",
      "I0903 07:15:13.083443 140518929565504 graph_util_impl.py:334] Froze 360 variables.\n",
      "INFO:tensorflow:Converted 360 variables to const ops.\n",
      "I0903 07:15:13.154691 140518929565504 graph_util_impl.py:394] Converted 360 variables to const ops.\n",
      "2020-09-03 07:15:13.338348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2020-09-03 07:15:13.338738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2020-09-03 07:15:13.338790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-09-03 07:15:13.338802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-09-03 07:15:13.338812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-09-03 07:15:13.338823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-09-03 07:15:13.338833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-09-03 07:15:13.338843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-09-03 07:15:13.338853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-03 07:15:13.339859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-09-03 07:15:13.339906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-09-03 07:15:13.339914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-09-03 07:15:13.339919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2020-09-03 07:15:13.339924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2020-09-03 07:15:13.340711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7408 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2020-09-03 07:15:13.341036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7603 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "WARNING:tensorflow:From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0903 07:15:13.680881 140518929565504 deprecation.py:323] From /home/bigdata/Documentos/proyecto_mario/tensorflow_object_detection_guide/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "I0903 07:15:13.681416 140518929565504 builder_impl.py:640] No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I0903 07:15:13.681493 140518929565504 builder_impl.py:460] No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: inference_graph_02_09_10_14/saved_model/saved_model.pb\n",
      "I0903 07:15:14.004466 140518929565504 builder_impl.py:425] SavedModel written to: inference_graph_02_09_10_14/saved_model/saved_model.pb\n",
      "INFO:tensorflow:Writing pipeline config file to inference_graph_02_09_10_14/pipeline.config\n",
      "I0903 07:15:14.029122 140518929565504 config_util.py:254] Writing pipeline config file to inference_graph_02_09_10_14/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "# ahora vamos a exportar este modelo como un grafo de inferencia. Este grafo se podrá usar para generar predicciones luego.\n",
    "# Debemos sustituir los parámetros de entrada [\"pipeline_config_path\",\"trained_checkpoint_prefix\",\"output_directory\"]\n",
    "# por los nuestros. Es recomendable elegir un nombre reconocible para la carpeta de salida, como por ejemplo\n",
    "# \"inference_graph\" seguido de la fecha y la hora\n",
    "!python3 object_detection/export_inference_graph.py --input_type image_tensor \\\n",
    "--pipeline_config_path training/mask_rcnn_inception_v2_coco.config \\\n",
    "--trained_checkpoint_prefix training/model.ckpt-2744\\\n",
    "--output_directory inference_graph_02_09_10_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t\tmodel.ckpt.index  saved_model\r\n",
      "frozen_inference_graph.pb\tmodel.ckpt.meta\r\n",
      "model.ckpt.data-00000-of-00001\tpipeline.config\r\n"
     ]
    }
   ],
   "source": [
    "!dir inference_graph_02_09_10_14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
