{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instalación de paquetes y verificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congrats, you are using 3.7.9  which is compatible with this notebook\n"
     ]
    }
   ],
   "source": [
    "# comprobamos que la versión de python sea inferior a 3.8, ya que para usar tensorflow 1.15 se recomienda usar python\n",
    "# 3.7 o inferior\n",
    "import sys\n",
    "import string\n",
    "python_version=sys.version.split(\"(\")[0]\n",
    "if int(sys.version.split(\".\")[1])>7:\n",
    "    print(\"you are using a python version higer than 3.7.x, please install python 3.7.x\")\n",
    "else:\n",
    "    print(\"congrats, you are using {} which is compatible with this notebook\".format(python_version))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.7.9: /home/bigdata/anaconda3/envs/test/bin/python3\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n",
      "/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/data_structures.py:669: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if not isinstance(wrapped_dict, collections.Mapping):\n",
      "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_experimental_model\n",
      "[       OK ] ModelBuilderTF1Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF1Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF1Test.test_session\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 21 tests in 0.085s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# si todo sale bien,el test debería correr y los resultados aparecerán debajo. Es normal si se salta alguno de los tests \n",
    "# que hay\n",
    "!python3 models/research/object_detection/builders/model_builder_tf1_test.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succesfully created validation split using:  15.0 % of data\n",
      "succesfully created test split using:  10.0 % of data\n",
      "succesfully created train split using:  75.0 % of data\n",
      "\u001b[34;42mimages_bb\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "\n",
      "3 directories\n"
     ]
    }
   ],
   "source": [
    "# vamos a dividir nuestras imágenes y anotaciones en splits de train, test y validación.\n",
    "# los argumentos -vr y -tr indican respectivamente los porcentajes de datos reservados para validación y test\n",
    "!python3 scripts/train_test_split.py -i images_bb -o images_bb -tr 0.1 -vr 0.15 -f JPG\n",
    "!tree -d images_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0011154.xml\n",
      "G0021262.xml\n",
      "G0051599.xml\n",
      "G0061723.xml\n",
      "G0051637.xml\n",
      "G0051597.xml\n",
      "G0031460.xml\n",
      "G0061737.xml\n",
      "G0021319.xml\n",
      "G0061746.xml\n",
      "G0051527.xml\n",
      "G0051642.xml\n",
      "G0011175.xml\n",
      "G0031435.xml\n",
      "G0011145.xml\n",
      "G0051577.xml\n",
      "G0021268.xml\n",
      "G0031483.xml\n",
      "G0011144.xml\n",
      "G0061816.xml\n",
      "G0021333.xml\n",
      "G0051576.xml\n",
      "G0031476.xml\n",
      "G0011193.xml\n",
      "G0011146.xml\n",
      "G0061798.xml\n",
      "G0051680.xml\n",
      "G0021327.xml\n",
      "G0061736.xml\n",
      "G0011227.xml\n",
      "G0061763.xml\n",
      "G0031438.xml\n",
      "G0061740.xml\n",
      "G0011138.xml\n",
      "G0051655.xml\n",
      "G0031439.xml\n",
      "G0011147.xml\n",
      "G0041505.xml\n",
      "G0061717.xml\n",
      "G0021372.xml\n",
      "G0061811.xml\n",
      "G0051572.xml\n",
      "G0031454.xml\n",
      "G0011150.xml\n",
      "G0031452.xml\n",
      "G0031386.xml\n",
      "G0061838.xml\n",
      "G0011159.xml\n",
      "G0011142.xml\n",
      "G0031431.xml\n",
      "G0051631.xml\n",
      "G0051636.xml\n",
      "G0031442.xml\n",
      "G0011210.xml\n",
      "G0011160.xml\n",
      "G0061755.xml\n",
      "G0011148.xml\n",
      "G0021357.xml\n",
      "G0061720.xml\n",
      "G0061696.xml\n",
      "G0021369.xml\n",
      "G0061745.xml\n",
      "G0011139.xml\n",
      "G0021281.xml\n",
      "G0041503.xml\n",
      "G0051645.xml\n",
      "G0021296.xml\n",
      "G0011156.xml\n",
      "G0011141.xml\n",
      "G0061684.xml\n",
      "G0031449.xml\n",
      "G0031414.xml\n",
      "G0061831.xml\n",
      "G0011149.xml\n",
      "G0051538.xml\n",
      "G0011143.xml\n",
      "G0051546.xml\n",
      "G0021371.xml\n",
      "G0041516.xml\n",
      "G0011152.xml\n",
      "G0051575.xml\n",
      "G0061757.xml\n",
      "G0011151.xml\n",
      "G0061700.xml\n",
      "G0061769.xml\n",
      "G0031396.xml\n",
      "G0011153.xml\n",
      "G0031443.xml\n",
      "G0011249.xml\n",
      "G0021356.xml\n",
      "G0011140.xml\n",
      "G0061853.xml\n",
      "G0011158.xml\n",
      "G0031475.xml\n",
      "G0011137.xml\n",
      "G0061709.xml\n",
      "G0011157.xml\n",
      "G0011239.xml\n",
      "G0011155.xml\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/json_to_xml.py -i images_bb/train -o images_bb/train\n",
    "!python3 scripts/json_to_xml.py -i images_bb/val -o images_bb/val\n",
    "!python3 scripts/json_to_xml.py -i images_bb/test -o images_bb/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: training/train.record\n",
      "Successfully created the TFRecord file: training/test.record\n",
      "Successfully created the TFRecord file: training/val.record\n"
     ]
    }
   ],
   "source": [
    "# ahora tenemos que generar los tfrecords usando estos dataset en formato coco\n",
    "!python3 scripts/generate_tfrecord.py -x images_bb/train -l training/label_map_bb.pbtxt -o training/train.record\n",
    "!python3 scripts/generate_tfrecord.py -x images_bb/test -l training/label_map_bb.pbtxt -o training/test.record\n",
    "!python3 scripts/generate_tfrecord.py -x images_bb/val -l training/label_map_bb.pbtxt -o training/val.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y exportación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0909 09:12:11.643194 140046260520768 model_lib.py:771] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 400000\n",
      "I0909 09:12:11.643353 140046260520768 config_util.py:552] Maybe overwriting train_steps: 400000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0909 09:12:11.643400 140046260520768 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I0909 09:12:11.643438 140046260520768 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0909 09:12:11.643476 140046260520768 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0909 09:12:11.643527 140046260520768 model_lib.py:787] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "I0909 09:12:11.643569 140046260520768 model_lib.py:822] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5e65c33ed0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0909 09:12:11.643832 140046260520768 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5e65c33ed0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5e65bc4290>) includes params argument, but params are not passed to Estimator.\n",
      "W0909 09:12:11.644034 140046260520768 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5e65bc4290>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I0909 09:12:11.644251 140046260520768 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0909 09:12:11.644357 140046260520768 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0909 09:12:11.644485 140046260520768 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0909 09:12:11.647741 140046260520768 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0909 09:12:11.664045 140046260520768 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0909 09:12:11.667242 140046260520768 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0909 09:12:11.681401 140046260520768 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0909 09:12:19.521302 140046260520768 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0909 09:12:19.589125 140046260520768 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0909 09:12:22.938572 140046260520768 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0909 09:12:25.777052 140046260520768 estimator.py:1148] Calling model_fn.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0909 09:12:25.797866 140046260520768 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0909 09:12:26.620193 140046260520768 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0909 09:12:26.710429 140046260520768 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0909 09:12:26.710677 140046260520768 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0909 09:12:27.165638 140046260520768 deprecation.py:506] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0909 09:12:27.591578 140046260520768 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0909 09:12:27.593157 140046260520768 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0909 09:12:27.603796 140046260520768 regularizers.py:99] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/core/losses.py:380: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0909 09:12:27.782821 140046260520768 deprecation.py:323] From /home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/object_detection/core/losses.py:380: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0909 09:12:30.263352 140046260520768 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0909 09:12:30.264189 140046260520768 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0909 09:12:31.524018 140046260520768 monitored_session.py:240] Graph was finalized.\n",
      "2020-09-09 09:12:31.524298: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-09-09 09:12:31.548448: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3799900000 Hz\n",
      "2020-09-09 09:12:31.549868: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5617f7119e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-09-09 09:12:31.549917: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-09-09 09:12:31.554034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-09-09 09:12:31.879638: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5617f714b240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-09-09 09:12:31.879702: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n",
      "2020-09-09 09:12:31.879721: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080, Compute Capability 6.1\n",
      "2020-09-09 09:12:31.882894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:17:00.0\n",
      "2020-09-09 09:12:31.883850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:65:00.0\n",
      "2020-09-09 09:12:31.920418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-09-09 09:12:31.922690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-09-09 09:12:31.924662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-09-09 09:12:31.925254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-09-09 09:12:31.927841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-09-09 09:12:31.929807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-09-09 09:12:31.935031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-09 09:12:31.940272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-09-09 09:12:31.940345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-09-09 09:12:31.942519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-09-09 09:12:31.942542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-09-09 09:12:31.942553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2020-09-09 09:12:31.942562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2020-09-09 09:12:31.944373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7408 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2020-09-09 09:12:31.945591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7603 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "I0909 09:12:34.256578 140046260520768 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0909 09:12:34.440859 140046260520768 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
      "I0909 09:12:38.137158 140046260520768 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
      "2020-09-09 09:12:42.435622: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-09-09 09:12:44.097419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-09 09:12:44.903374: W tensorflow/stream_executor/cuda/ptxas_utils.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.\n",
      "INFO:tensorflow:loss = 5.5050106, step = 0\n",
      "I0909 09:12:46.925459 140046260520768 basic_session_run_hooks.py:262] loss = 5.5050106, step = 0\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# entrenamos el modelo usando estos tfrecords. El modelo resultante se guardará el carpeta training\n",
    "!python3 models/research/object_detection/model_main.py --alsologtostderr \\\n",
    "--model_dir=training/ \\\n",
    "--pipeline_config_path=training/faster_rcnn_inception_v2_coco.config \\\n",
    "--num_train_steps=400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aquí nos vamos a fijar en los archivos model.ckpt y vamos a buscar el que tenga el número más alto, ya que este número\n",
    "# indica el step del proceso de entrenamiento en el que se realizó el checkpoint del modelo\n",
    "!dir training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por si no lo ves claro, corriendo esto te dirá qué debes poner en el script siguiente que generará el grafo de inferencia\n",
    "import glob\n",
    "import os\n",
    "max_step=0\n",
    "for file in glob.glob(\"training/*\"):\n",
    "    if (\"model.ckpt\" in  file):\n",
    "        step=int (file.split(os.sep)[1].split(\".\")[1].split(\"-\")[1])\n",
    "        max_step= step if step>max_step else max_step\n",
    "print(\"En el campo trained_checkpoint debes poner lo siguiente: \\ntraining/model.ckpt-\"+str(max_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora vamos a exportar este modelo como un grafo de inferencia. Este grafo se podrá usar para generar predicciones luego.\n",
    "# Debemos sustituir los parámetros de entrada [\"pipeline_config_path\",\"trained_checkpoint_prefix\",\"output_directory\"]\n",
    "# por los nuestros. Es recomendable elegir un nombre reconocible para la carpeta de salida, como por ejemplo\n",
    "# \"inference_graph\" seguido de la fecha y la hora\n",
    "!python3 models/research/object_detection/export_inference_graph.py --input_type image_tensor \\\n",
    "--pipeline_config_path training/mask_rcnn_inception_v2_coco.config \\\n",
    "--trained_checkpoint_prefix training/model.ckpt-2744\\\n",
    "--output_directory inference_graph_02_09_10_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir inference_graph_02_09_10_14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
