{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instalación de paquetes y verificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congrats, you are using 3.7.9  which is compatible with this notebook\n"
     ]
    }
   ],
   "source": [
    "# comprobamos que la versión de python sea inferior a 3.8, ya que para usar tensorflow 1.15 se recomienda usar python\n",
    "# 3.7 o inferior\n",
    "import sys\n",
    "import string\n",
    "python_version=sys.version.split(\"(\")[0]\n",
    "if int(sys.version.split(\".\")[1])>7:\n",
    "    print(\"you are using a python version higer than 3.7.x, please install python 3.7.x\")\n",
    "else:\n",
    "    print(\"congrats, you are using {} which is compatible with this notebook\".format(python_version))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.7.9: /home/bigdata/anaconda3/envs/test/bin/python3\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n",
      "/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/data_structures.py:669: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if not isinstance(wrapped_dict, collections.Mapping):\n",
      "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_experimental_model\n",
      "[       OK ] ModelBuilderTF1Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
      "[       OK ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
      "[       OK ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF1Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF1Test.test_session\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
      "[       OK ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 21 tests in 0.151s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# si todo sale bien,el test debería correr y los resultados aparecerán debajo. Es normal si se salta alguno de los tests \n",
    "# que hay\n",
    "!python3 models/research/object_detection/builders/model_builder_tf1_test.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succesfully created validation split using:  15.0 % of data\n",
      "succesfully created test split using:  10.0 % of data\n",
      "succesfully created train split using:  75.0 % of data\n",
      "\u001b[01;34mimages\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "\n",
      "3 directories\n"
     ]
    }
   ],
   "source": [
    "# vamos a dividir nuestras imágenes y anotaciones en splits de train, test y validación.\n",
    "# los argumentos -vr y -tr indican respectivamente los porcentajes de datos reservados para validación y test.\n",
    "# el argumento -f indica el formato de las imágenes\n",
    "!python3 scripts/train_test_split.py -i images_masks -o images_masks -tr 0.1 -vr 0.15 -f jpg\n",
    "!tree -d images_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset: images/train/coco\n",
      "Generating dataset from: images/train/images_frame8050.json\n",
      "Generating dataset from: images/train/images_frame3100.json\n",
      "Generating dataset from: images/train/images_frame7900.json\n",
      "Generating dataset from: images/train/images_frame5800.json\n",
      "Generating dataset from: images/train/images_frame10250.json\n",
      "Generating dataset from: images/train/images_frame5300.json\n",
      "Generating dataset from: images/train/images_frame3750.json\n",
      "Generating dataset from: images/train/images_frame10150.json\n",
      "Generating dataset from: images/train/images_frame7350.json\n",
      "Generating dataset from: images/train/images_frame8700.json\n",
      "Generating dataset from: images/train/images_frame1350.json\n",
      "Generating dataset from: images/train/images_frame3350.json\n",
      "Generating dataset from: images/train/images_frame8500.json\n",
      "Generating dataset from: images/train/images_frame1750.json\n",
      "Generating dataset from: images/train/images_frame1550.json\n",
      "Generating dataset from: images/train/images_frame9400.json\n",
      "Generating dataset from: images/train/images_frame9200.json\n",
      "Generating dataset from: images/train/images_frame10100.json\n",
      "Generating dataset from: images/train/images_frame8800.json\n",
      "Generating dataset from: images/train/images_frame7450.json\n",
      "Generating dataset from: images/train/images_frame5450.json\n",
      "Generating dataset from: images/train/images_frame3250.json\n",
      "Generating dataset from: images/train/images_frame9100.json\n",
      "Generating dataset from: images/train/images_frame900.json\n",
      "Generating dataset from: images/train/images_frame3300.json\n",
      "Generating dataset from: images/train/images_frame9000.json\n",
      "Generating dataset from: images/train/images_frame9950.json\n",
      "Generating dataset from: images/train/images_frame8450.json\n",
      "Generating dataset from: images/train/images_frame8400.json\n",
      "Generating dataset from: images/train/images_frame2350.json\n",
      "Generating dataset from: images/train/images_frame5700.json\n",
      "Generating dataset from: images/train/images_frame1650.json\n",
      "Generating dataset from: images/train/images_frame9450.json\n",
      "Generating dataset from: images/train/images_frame1200.json\n",
      "Generating dataset from: images/train/images_frame2100.json\n",
      "Generating dataset from: images/train/images_frame4850.json\n",
      "Generating dataset from: images/train/images_frame9600.json\n",
      "Generating dataset from: images/train/images_frame1050.json\n",
      "Generating dataset from: images/train/images_frame4550.json\n",
      "Generating dataset from: images/train/images_frame7650.json\n",
      "Generating dataset from: images/train/images_frame1250.json\n",
      "Generating dataset from: images/train/images_frame1450.json\n",
      "Generating dataset from: images/train/images_frame4000.json\n",
      "Generating dataset from: images/train/images_frame8150.json\n",
      "Generating dataset from: images/train/images_frame5250.json\n",
      "Generating dataset from: images/train/images_frame3200.json\n",
      "Generating dataset from: images/train/images_frame4500.json\n",
      "Generating dataset from: images/train/images_frame3700.json\n",
      "Generating dataset from: images/train/images_frame4400.json\n",
      "Generating dataset from: images/train/images_frame2600.json\n",
      "Generating dataset from: images/train/images_frame3550.json\n",
      "Generating dataset from: images/train/images_frame2200.json\n",
      "Generating dataset from: images/train/images_frame2650.json\n",
      "Generating dataset from: images/train/images_frame7750.json\n",
      "Generating dataset from: images/train/images_frame8900.json\n",
      "Generating dataset from: images/train/images_frame7600.json\n",
      "Generating dataset from: images/train/images_frame1950.json\n",
      "Generating dataset from: images/train/images_frame6900.json\n",
      "Generating dataset from: images/train/images_frame5500.json\n",
      "Generating dataset from: images/train/images_frame7050.json\n",
      "Generating dataset from: images/train/images_frame4250.json\n",
      "Generating dataset from: images/train/images_frame7700.json\n",
      "Generating dataset from: images/train/images_frame2400.json\n",
      "Generating dataset from: images/train/images_frame2900.json\n",
      "Generating dataset from: images/train/images_frame3400.json\n",
      "Generating dataset from: images/train/images_frame4950.json\n",
      "Generating dataset from: images/train/images_frame8850.json\n",
      "Generating dataset from: images/train/images_frame7550.json\n",
      "Generating dataset from: images/train/images_frame8750.json\n",
      "Generating dataset from: images/train/images_frame7200.json\n",
      "Generating dataset from: images/train/images_frame7400.json\n",
      "Generating dataset from: images/train/images_frame3800.json\n",
      "Generating dataset from: images/train/images_frame1400.json\n",
      "Generating dataset from: images/train/images_frame7100.json\n",
      "Generating dataset from: images/train/images_frame9050.json\n",
      "Generating dataset from: images/train/images_frame8350.json\n",
      "Generating dataset from: images/train/images_frame7950.json\n",
      "Generating dataset from: images/train/images_frame4800.json\n",
      "Generating dataset from: images/train/images_frame3450.json\n",
      "Generating dataset from: images/train/images_frame4900.json\n",
      "Generating dataset from: images/train/images_frame9500.json\n",
      "Generating dataset from: images/train/images_frame4350.json\n",
      "Generating dataset from: images/train/images_frame2250.json\n",
      "Generating dataset from: images/train/images_frame7500.json\n",
      "Generating dataset from: images/train/images_frame4200.json\n",
      "Generating dataset from: images/train/images_frame8600.json\n",
      "Generating dataset from: images/train/images_frame9150.json\n",
      "Generating dataset from: images/train/images_frame4050.json\n",
      "Generating dataset from: images/train/images_frame3050.json\n",
      "Generating dataset from: images/train/images_frame7150.json\n",
      "Generating dataset from: images/train/images_frame2450.json\n",
      "Generating dataset from: images/train/images_frame2550.json\n",
      "Generating dataset from: images/train/images_frame2150.json\n",
      "Generating dataset from: images/train/images_frame9550.json\n",
      "Generating dataset from: images/train/images_frame1100.json\n",
      "Generating dataset from: images/train/images_frame8950.json\n",
      "Generating dataset from: images/train/images_frame4100.json\n",
      "Generating dataset from: images/train/images_frame8200.json\n",
      "Generating dataset from: images/train/images_frame9300.json\n",
      "Generating dataset from: images/train/images_frame4750.json\n",
      "Generating dataset from: images/train/images_frame7800.json\n",
      "Generating dataset from: images/train/images_frame2700.json\n",
      "Generating dataset from: images/train/images_frame3850.json\n",
      "Generating dataset from: images/train/images_frame3950.json\n",
      "Generating dataset from: images/train/images_frame1600.json\n",
      "Generating dataset from: images/train/images_frame9850.json\n",
      "Generating dataset from: images/train/images_frame10200.json\n",
      "Generating dataset from: images/train/images_frame8300.json\n",
      "Generating dataset from: images/train/images_frame3500.json\n",
      "Generating dataset from: images/train/images_frame8650.json\n",
      "Generating dataset from: images/train/images_frame4150.json\n",
      "Generating dataset from: images/train/images_frame4700.json\n",
      "Generating dataset from: images/train/images_frame4650.json\n",
      "Generating dataset from: images/train/images_frame3650.json\n",
      "Generating dataset from: images/train/images_frame4600.json\n",
      "Generating dataset from: images/train/images_frame1150.json\n",
      "Generating dataset from: images/train/images_frame3900.json\n",
      "Creating dataset: images/test/coco\n",
      "Generating dataset from: images/test/images_frame5200.json\n",
      "Generating dataset from: images/test/images_frame1700.json\n",
      "Generating dataset from: images/test/images_frame5150.json\n",
      "Generating dataset from: images/test/images_frame10050.json\n",
      "Generating dataset from: images/test/images_frame3150.json\n",
      "Generating dataset from: images/test/images_frame2500.json\n",
      "Generating dataset from: images/test/images_frame6950.json\n",
      "Generating dataset from: images/test/images_frame1000.json\n",
      "Generating dataset from: images/test/images_frame8250.json\n",
      "Generating dataset from: images/test/images_frame10000.json\n",
      "Generating dataset from: images/test/images_frame7850.json\n",
      "Generating dataset from: images/test/images_frame5750.json\n",
      "Generating dataset from: images/test/images_frame1500.json\n",
      "Generating dataset from: images/test/images_frame8100.json\n",
      "Generating dataset from: images/test/images_frame9900.json\n",
      "Generating dataset from: images/test/images_frame8000.json\n",
      "Creating dataset: images/val/coco\n",
      "Generating dataset from: images/val/images_frame2000.json\n",
      "Generating dataset from: images/val/images_frame2750.json\n",
      "Generating dataset from: images/val/images_frame2950.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset from: images/val/images_frame2300.json\n",
      "Generating dataset from: images/val/images_frame9650.json\n",
      "Generating dataset from: images/val/images_frame2050.json\n",
      "Generating dataset from: images/val/images_frame9750.json\n",
      "Generating dataset from: images/val/images_frame9700.json\n",
      "Generating dataset from: images/val/images_frame9250.json\n",
      "Generating dataset from: images/val/images_frame7000.json\n",
      "Generating dataset from: images/val/images_frame9350.json\n",
      "Generating dataset from: images/val/images_frame1300.json\n",
      "Generating dataset from: images/val/images_frame5350.json\n",
      "Generating dataset from: images/val/images_frame5550.json\n",
      "Generating dataset from: images/val/images_frame950.json\n",
      "Generating dataset from: images/val/images_frame8550.json\n",
      "Generating dataset from: images/val/images_frame4300.json\n",
      "Generating dataset from: images/val/images_frame9800.json\n",
      "Generating dataset from: images/val/images_frame7300.json\n",
      "Generating dataset from: images/val/images_frame3000.json\n",
      "Generating dataset from: images/val/images_frame4450.json\n",
      "Generating dataset from: images/val/images_frame7250.json\n",
      "Generating dataset from: images/val/images_frame10300.json\n",
      "Generating dataset from: images/val/images_frame3600.json\n",
      "\u001b[01;34mimages\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "│   └── \u001b[01;34mcoco\u001b[00m\n",
      "│       ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "│       └── \u001b[01;34mVisualization\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   └── \u001b[01;34mcoco\u001b[00m\n",
      "│       ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "│       └── \u001b[01;34mVisualization\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "    └── \u001b[01;34mcoco\u001b[00m\n",
      "        ├── \u001b[01;34mJPEGImages\u001b[00m\n",
      "        └── \u001b[01;34mVisualization\u001b[00m\n",
      "\n",
      "12 directories\n"
     ]
    }
   ],
   "source": [
    "# vamos a convertir estas fotos en y anotaciones en datasets de formato COCO. Tenemos que hacerlo para los sets de train\n",
    "# test y validación. Tenemos que pasar como argumento archivo txt con los labels siguiendo el formato indiado en la\n",
    "# documentación oficial de labelme https://github.com/wkentaro/labelme/tree/master/examples/instance_segmentation. Un ejemplo\n",
    "# de cómo debe ser este archivo se muestra debajo\n",
    "!python3 scripts/labelme2coco.py images_masks/train images_masks/train/coco --labels training_masks/labels.txt\n",
    "!python3 scripts/labelme2coco.py images_masks/test images_masks/test/coco --labels training_masks/labels.txt\n",
    "!python3 scripts/labelme2coco.py images_masks/val images_masks/val/coco --labels training_masks/labels.txt\n",
    "!tree -d images_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"labels_txt.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'images/test/coco/*': No such file or directory\n",
      "mv: cannot stat 'images/train/coco/*': No such file or directory\n",
      "mv: cannot stat 'images/val/coco/*': No such file or directory\n",
      "\u001b[01;34mimages\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "\n",
      "3 directories\n"
     ]
    }
   ],
   "source": [
    "# ahora borramos las imágenes y anotaciones de las carpetas train, test y val, ya que la carpeta coco dentro de cada \n",
    "# una de estas carpetas ya contiene las imágenes originales\n",
    "!rm images_masks/test/*\n",
    "!mv images_masks/test/coco/* images_masks/test\n",
    "!rm -rf images_masks/test/coco \n",
    "\n",
    "!rm images_masks/train/*\n",
    "!mv images_masks/train/coco/* images_masks/train\n",
    "!rm -rf images_masks/train/coco \n",
    "\n",
    "!rm images_masks/val/*\n",
    "!mv images_masks/val/coco/* images_masks/val\n",
    "!rm -rf images_masks/val/coco \n",
    "\n",
    "!tree -d images_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"models/research/object_detection/dataset_tools/create_coco_tf_record.py\", line 518, in <module>\r\n",
      "    tf.app.run()\r\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/absl/app.py\", line 300, in run\r\n",
      "    _run_main(main, args)\r\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/absl/app.py\", line 251, in _run_main\r\n",
      "    sys.exit(main(argv))\r\n",
      "  File \"models/research/object_detection/dataset_tools/create_coco_tf_record.py\", line 498, in main\r\n",
      "    remove_non_person_images=FLAGS.remove_non_person_images)\r\n",
      "  File \"models/research/object_detection/dataset_tools/create_coco_tf_record.py\", line 392, in _create_tf_record_from_coco_annotations\r\n",
      "    groundtruth_data = json.load(fid)\r\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/json/__init__.py\", line 293, in load\r\n",
      "    return loads(fp.read(),\r\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\r\n",
      "    self._preread_check()\r\n",
      "  File \"/home/bigdata/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\r\n",
      "    compat.as_bytes(self.__name), 1024 * 512)\r\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: images/train/annotations.json; No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# ahora tenemos que generar los tfrecords usando estos dataset en formato coco\n",
    "!python3 models/research/object_detection/dataset_tools/create_coco_tf_record.py --logtostderr \\\n",
    "--train_image_dir=images_masks/train \\\n",
    "--val_image_dir=images_masks/val \\\n",
    "--test_image_dir=images_masks/test \\\n",
    "--train_annotations_file=images_masks/train/annotations.json \\\n",
    "--val_annotations_file=images_masks/val/annotations.json \\\n",
    "--testdev_annotations_file=images_masks/test/annotations.json \\\n",
    "--output_dir=training_masks/tfrecord \\\n",
    "--include_masks=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y exportación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el modelo usando estos tfrecords. El modelo resultante se guardará el carpeta training_masks\n",
    "!python3 models/research/object_detection/model_main.py --alsologtostderr \\\n",
    "--model_dir=training_masks/ \\\n",
    "--pipeline_config_path=training_masks/mask_rcnn_inception_v2_coco.config \\\n",
    "--num_train_steps=400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aquí nos vamos a fijar en los archivos model.ckpt y vamos a buscar el que tenga el número más alto, ya que este número\n",
    "# indica el step del proceso de entrenamiento en el que se realizó el checkpoint del modelo\n",
    "!dir training_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por si no lo ves claro, corriendo esto te dirá qué debes poner en el script siguiente que generará el grafo de inferencia\n",
    "import glob\n",
    "import os\n",
    "max_step=0\n",
    "for file in glob.glob(\"training_masks/*\"):\n",
    "    if (\"model.ckpt\" in  file):\n",
    "        step=int (file.split(os.sep)[1].split(\".\")[1].split(\"-\")[1])\n",
    "        max_step= step if step>max_step else max_step\n",
    "print(\"En el campo trained_checkpoint debes poner lo siguiente: \\ntraining_masks/model.ckpt-\"+str(max_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora vamos a exportar este modelo como un grafo de inferencia. Este grafo se podrá usar para generar predicciones luego.\n",
    "# Debemos sustituir los parámetros de entrada [\"pipeline_config_path\",\"trained_checkpoint_prefix\",\"output_directory\"]\n",
    "# por los nuestros. Es recomendable elegir un nombre reconocible para la carpeta de salida, como por ejemplo\n",
    "# \"inference_graph\" seguido del modelo entrenado y la fecha y la hora\n",
    "!python3 models/research/object_detection/export_inference_graph.py --input_type image_tensor \\\n",
    "--pipeline_config_path training_masks/mask_rcnn_inception_v2_coco.config \\\n",
    "--trained_checkpoint_prefix training_masks/model.ckpt-2744 \\\n",
    "--output_directory inference_graph_mask_rcnn_02_09_10_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir inference_graph_mask_rcnn_02_09_10_14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generando predicciones en imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 scripts/predict_on_images.py \\\n",
    "-i images_masks/test \\\n",
    "-o predicions_image_masks \\\n",
    "-m inference_graph_02_09_10_14 \\\n",
    "-l training_masks/label_map.pbtxt\n",
    "-f jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
